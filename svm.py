# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ehhv9B3Zlx9mhWCGbGJp1G5NbZUvLkUc
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import hinge_loss, accuracy_score
import matplotlib.pyplot as plt

# Load dataset
data_path = 'spambase.data'  # Update this to your actual file path
data = pd.read_csv(data_path, header=None)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# Split dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the SGDClassifier with hinge loss
model = SGDClassifier(loss='hinge', learning_rate='optimal', max_iter=1, tol=None, warm_start=True)

epochs = 250
train_losses = []
test_losses = []
train_accuracies = []
test_accuracies = []

for epoch in range(epochs):
    model.fit(X_train_scaled, y_train)

    # Predict on training and testing data
    train_predictions = model.decision_function(X_train_scaled)
    test_predictions = model.decision_function(X_test_scaled)

    # Calculate hinge loss for training and testing
    train_loss = hinge_loss(y_train, train_predictions)
    test_loss = hinge_loss(y_test, test_predictions)
    train_losses.append(train_loss)
    test_losses.append(test_loss)

    # Calculate accuracy for training and testing
    train_accuracy = accuracy_score(y_train, model.predict(X_train_scaled))
    test_accuracy = accuracy_score(y_test, model.predict(X_test_scaled))
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)

    # Print epoch number and test accuracy for each epoch
    print(f"Epoch {epoch + 1}/{epochs} - Test Accuracy: {test_accuracy:.4f}")

# Print final test accuracy
print(f"Final Test Accuracy: {test_accuracy:.4f}")

# Plotting
plt.figure(figsize=(14, 7))

# Plot training and testing losses
plt.subplot(1, 2, 1)
plt.plot(range(epochs), train_losses, label='Training Loss')
plt.plot(range(epochs), test_losses, label='Testing Loss')
plt.title('Training and Testing Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Hinge Loss')
plt.legend()

# Plot training and testing accuracies
plt.subplot(1, 2, 2)
plt.plot(range(epochs), train_accuracies, label='Training Accuracy')
plt.plot(range(epochs), test_accuracies, label='Testing Accuracy')
plt.title('Training and Testing Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# Load dataset
data_path = 'spambase.data'  # Update this to your actual file path
data = pd.read_csv(data_path, header=None)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# Split dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define a range of learning rates to explore
learning_rates = [0.01, 0.1,1]
test_accuracies = []

for lr in learning_rates:
    # Initialize the SGDClassifier with hinge loss and the current learning rate
    model = SGDClassifier(loss='hinge', learning_rate='constant', eta0=lr, max_iter=1000, tol=1e-3, random_state=42)

    # Train the model
    model.fit(X_train_scaled, y_train)

    # Evaluate the model on the test set
    test_accuracy = accuracy_score(y_test, model.predict(X_test_scaled))
    test_accuracies.append(test_accuracy)

    # Print learning rate and test accuracy
    print(f"Learning Rate: {lr} - Test Accuracy: {test_accuracy:.4f}")



# Plot the effect of learning rate on test accuracy
plt.figure(figsize=(8, 6))
plt.plot(learning_rates, test_accuracies, marker='o', linestyle='-', color='blue')
plt.title('Effect of Learning Rate on Test Accuracy')
plt.xlabel('Learning Rate')
plt.ylabel('Test Accuracy')
plt.xscale('log')  # Because we're covering a broad range of values
plt.show()

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import pandas as pd

# Load dataset
data_path = 'spambase.data'  # Update this to your actual file path
data = pd.read_csv(data_path, header=None)
X = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

# Split dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define a pipeline that includes scaling and the SVM classifier
pipe = make_pipeline(StandardScaler(), SVC())

# Define the parameter grid to search over
param_grid = {'svc__C': [0.01, 0.1, 1, 10, 100]}

# Initialize the grid search with cross-validation
grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')

# Perform the grid search on the training data
grid_search.fit(X_train, y_train)

# Print the best value of C
print("Best value of C:", grid_search.best_params_['svc__C'])

# Evaluate the best model on the test set
test_score = grid_search.score(X_test, y_test)
print("Test set score with the best C:", test_score)